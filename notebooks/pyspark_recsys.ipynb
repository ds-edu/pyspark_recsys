{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7015cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, DateType, FloatType, TimestampType, ArrayType\n",
    "from pyspark.sql.functions import col, sum, isnan, isnull, isnotnull, when, countDistinct, count, regexp_replace, split, month, year, size, element_at, struct, trim, avg, expr, lit\n",
    "from pyspark.sql.functions import concat, concat_ws, rand, collect_list, struct\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75621ae6",
   "metadata": {},
   "source": [
    "#### File sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a5aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliances\n",
    "url_meta = 'https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_Appliances.jsonl.gz'\n",
    "url_ratings = 'https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/Appliances.jsonl.gz'\n",
    "\n",
    "\n",
    "# # Electronics\n",
    "# url_meta = 'https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_Electronics.jsonl.gz'\n",
    "# url_ratings = 'https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/Electronics.jsonl.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f485a1",
   "metadata": {},
   "source": [
    "#### Generating reduced size dummy test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d49c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_sampling(url, chunk_size, sample_size, random_state=None):\n",
    "    \"\"\"\n",
    "    Reads a JSON file in chunks, samples from each chunk, and returns a combined sample.\n",
    "\n",
    "    Args:\n",
    "        url (str): JSON file url\n",
    "        chunk_size (int): Number of rows to read in each chunk.\n",
    "        sample_size (int): Total number of rows to sample.\n",
    "        random_state (int, optional): Seed for random sampling. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the sampled rows.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "\n",
    "    sampled_chunks = []\n",
    "    total_rows = 0\n",
    "\n",
    "    for chunk in pd.read_json(url, lines=True, chunksize=chunk_size):\n",
    "       \n",
    "        chunk_sample_size = min(sample_size - total_rows, len(chunk))\n",
    "        if chunk_sample_size > 0:\n",
    "            sampled_chunk = chunk.sample(n=chunk_sample_size, random_state=random_state)\n",
    "            sampled_chunks.append(sampled_chunk)\n",
    "            total_rows += chunk_sample_size\n",
    "        if total_rows >= sample_size:\n",
    "            break\n",
    "\n",
    "    return pd.concat(sampled_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179dfb94",
   "metadata": {},
   "source": [
    "#### Reduce samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf83f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute UDF and save dummy files locally\n",
    "\n",
    "df_reviews = read_json_sampling(url_ratings, 100, 500, 33)\n",
    "df_meta = read_json_sampling(url_meta, 100, 500, 33)\n",
    "\n",
    "df_reviews.to_json('./data/reduced_app_reviews.jsonl.gz', orient='records', lines='true', compression='gzip')\n",
    "df_meta.to_json('./data/reduced_app_meta.jsonl.gz', orient='records', lines='true', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf925e3",
   "metadata": {},
   "source": [
    "#### Spark sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491e9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/05/22 10:21:59 WARN Utils: Your hostname, DPC resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/05/22 10:21:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/22 10:22:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"30g\") \\\n",
    "    .appName(\"RecSys2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05279bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.caseSensitive', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bd1b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RecSys2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f91da5273e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9429f",
   "metadata": {},
   "source": [
    "#### Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26454e",
   "metadata": {},
   "source": [
    "###### Via URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b0a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_meta = spark.read.json(url_meta)\n",
    "# # df_meta = spark.read.json(url_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8632a",
   "metadata": {},
   "source": [
    "###### Locally stored files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2bac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 10:22:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# Reduced files\n",
    "\n",
    "df_meta = spark.read.json('./data/reduced_app_meta.jsonl.gz'  )\n",
    "df_ratings = spark.read.json('./data/reduced_app_reviews.jsonl.gz' )\n",
    "\n",
    "#Full files\n",
    "\n",
    "# df_meta = spark.read.json('data/meta_Appliances.jsonl.gz')\n",
    "# df_ratings = spark.read.json('data/Appliances.jsonl.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dbe41",
   "metadata": {},
   "source": [
    "### Cleaning Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eba431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (500, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f'Metadata shape: ({df_meta.count()}, {len(df_meta.columns)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61a307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- bought_together: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- details: struct (nullable = true)\n",
      " |    |-- Access Location: string (nullable = true)\n",
      " |    |-- Age Range (Description): string (nullable = true)\n",
      " |    |-- Air Flow Capacity: string (nullable = true)\n",
      " |    |-- Airflow Displacement: string (nullable = true)\n",
      " |    |-- Alarm: string (nullable = true)\n",
      " |    |-- Amperage Capacity: string (nullable = true)\n",
      " |    |-- Annual Energy Consumption: string (nullable = true)\n",
      " |    |-- Are Batteries Included: string (nullable = true)\n",
      " |    |-- Assembly required: string (nullable = true)\n",
      " |    |-- Backlight: string (nullable = true)\n",
      " |    |-- Batteries: string (nullable = true)\n",
      " |    |-- Batteries Included?: string (nullable = true)\n",
      " |    |-- Batteries Required?: string (nullable = true)\n",
      " |    |-- Batteries required: string (nullable = true)\n",
      " |    |-- Battery Cell Type: string (nullable = true)\n",
      " |    |-- Best Sellers Rank: struct (nullable = true)\n",
      " |    |    |-- Amazon Renewed: long (nullable = true)\n",
      " |    |    |-- Appliances: long (nullable = true)\n",
      " |    |    |-- Beverage Refrigerators: long (nullable = true)\n",
      " |    |    |-- Chest Freezers: long (nullable = true)\n",
      " |    |    |-- Clothes Dryer Replacement Lint Screens: long (nullable = true)\n",
      " |    |    |-- Clothes Dryer Replacement Vents: long (nullable = true)\n",
      " |    |    |-- Clothes Washer Replacement Doors: long (nullable = true)\n",
      " |    |    |-- Clothes Washer Replacement Drain Pumps: long (nullable = true)\n",
      " |    |    |-- Clothes Washing Machines: long (nullable = true)\n",
      " |    |    |-- Commercial Bag Sealers: long (nullable = true)\n",
      " |    |    |-- Commercial Shrink Wrappers: long (nullable = true)\n",
      " |    |    |-- Compact Refrigerators: long (nullable = true)\n",
      " |    |    |-- Cooktop Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Cooktops: long (nullable = true)\n",
      " |    |    |-- Dishwasher Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Dishwasher Replacement Baskets: long (nullable = true)\n",
      " |    |    |-- Dishwasher Replacement Hoses: long (nullable = true)\n",
      " |    |    |-- Disposable Coffee Filters: long (nullable = true)\n",
      " |    |    |-- Dryer Replacement Parts: long (nullable = true)\n",
      " |    |    |-- Espresso Steaming Pitchers: long (nullable = true)\n",
      " |    |    |-- Freezer Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Health & Household: long (nullable = true)\n",
      " |    |    |-- Home & Kitchen: long (nullable = true)\n",
      " |    |    |-- Humidifier Accessories: long (nullable = true)\n",
      " |    |    |-- Humidifier Humidity Meters: long (nullable = true)\n",
      " |    |    |-- Humidifier Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Humidifier Replacement Wicks: long (nullable = true)\n",
      " |    |    |-- Ice Makers: long (nullable = true)\n",
      " |    |    |-- In-Refrigerator Water Filters: long (nullable = true)\n",
      " |    |    |-- Industrial & Scientific: long (nullable = true)\n",
      " |    |    |-- Jugs: long (nullable = true)\n",
      " |    |    |-- Kitchen & Dining: long (nullable = true)\n",
      " |    |    |-- Oven Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Paper & Plastic Household Supplies: long (nullable = true)\n",
      " |    |    |-- Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Permanent Coffee Filters: long (nullable = true)\n",
      " |    |    |-- Portable Clothes Washing Machines: long (nullable = true)\n",
      " |    |    |-- Portable Dryers: long (nullable = true)\n",
      " |    |    |-- Range Accessories: long (nullable = true)\n",
      " |    |    |-- Range Hood Filters: long (nullable = true)\n",
      " |    |    |-- Range Hoods: long (nullable = true)\n",
      " |    |    |-- Range Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Range Replacement Burners: long (nullable = true)\n",
      " |    |    |-- Range Replacement Drip Pans: long (nullable = true)\n",
      " |    |    |-- Range Replacement Knobs: long (nullable = true)\n",
      " |    |    |-- Refrigerator Egg Trays: long (nullable = true)\n",
      " |    |    |-- Refrigerator Parts & Accessories: long (nullable = true)\n",
      " |    |    |-- Refrigerator Replacement Bins: long (nullable = true)\n",
      " |    |    |-- Refrigerator Replacement Handles: long (nullable = true)\n",
      " |    |    |-- Refrigerator Replacement Ice Makers: long (nullable = true)\n",
      " |    |    |-- Refrigerator Replacement Motors: long (nullable = true)\n",
      " |    |    |-- Refrigerator Replacement Shelves: long (nullable = true)\n",
      " |    |    |-- Refrigerators: long (nullable = true)\n",
      " |    |    |-- Reusable Coffee Filters: long (nullable = true)\n",
      " |    |    |-- Tools & Home Improvement: long (nullable = true)\n",
      " |    |    |-- Washer Parts & Accessories: long (nullable = true)\n",
      " |    |-- Brand: string (nullable = true)\n",
      " |    |-- Brand Name: string (nullable = true)\n",
      " |    |-- Bulb Base: string (nullable = true)\n",
      " |    |-- Bulb Shape Size: string (nullable = true)\n",
      " |    |-- Burner type: string (nullable = true)\n",
      " |    |-- Capacity: string (nullable = true)\n",
      " |    |-- Capacity Name: string (nullable = true)\n",
      " |    |-- Capacity Total: string (nullable = true)\n",
      " |    |-- Care instructions: string (nullable = true)\n",
      " |    |-- Center To Center Spacing: string (nullable = true)\n",
      " |    |-- Certification: string (nullable = true)\n",
      " |    |-- Closure Type: string (nullable = true)\n",
      " |    |-- Color: string (nullable = true)\n",
      " |    |-- Color Temperature: string (nullable = true)\n",
      " |    |-- Compatible Device: string (nullable = true)\n",
      " |    |-- Compatible Devices: string (nullable = true)\n",
      " |    |-- Configuration: string (nullable = true)\n",
      " |    |-- Connectivity Technology: string (nullable = true)\n",
      " |    |-- Connector Type: string (nullable = true)\n",
      " |    |-- Contains Liquid Contents: string (nullable = true)\n",
      " |    |-- Control Console: string (nullable = true)\n",
      " |    |-- Control Method: string (nullable = true)\n",
      " |    |-- Control Type: string (nullable = true)\n",
      " |    |-- Controller Type: string (nullable = true)\n",
      " |    |-- Controls Type: string (nullable = true)\n",
      " |    |-- Cooling Power: string (nullable = true)\n",
      " |    |-- Cooling Vents: string (nullable = true)\n",
      " |    |-- Cord Length: string (nullable = true)\n",
      " |    |-- Country of Origin: string (nullable = true)\n",
      " |    |-- Cycle Options: string (nullable = true)\n",
      " |    |-- Date First Available: string (nullable = true)\n",
      " |    |-- Defrost: string (nullable = true)\n",
      " |    |-- Defrost System: string (nullable = true)\n",
      " |    |-- Department: string (nullable = true)\n",
      " |    |-- Diameter: string (nullable = true)\n",
      " |    |-- Domestic Shipping: string (nullable = true)\n",
      " |    |-- Door Hinges: string (nullable = true)\n",
      " |    |-- Door Material Type: string (nullable = true)\n",
      " |    |-- Drawer Type: string (nullable = true)\n",
      " |    |-- Duration: string (nullable = true)\n",
      " |    |-- Efficiency: string (nullable = true)\n",
      " |    |-- Energy Star: string (nullable = true)\n",
      " |    |-- Exterior: string (nullable = true)\n",
      " |    |-- Exterior Finish: string (nullable = true)\n",
      " |    |-- External Testing Certification: string (nullable = true)\n",
      " |    |-- Finish: string (nullable = true)\n",
      " |    |-- Finish Type: string (nullable = true)\n",
      " |    |-- Finish types: string (nullable = true)\n",
      " |    |-- Floor Area: string (nullable = true)\n",
      " |    |-- Flow Rate: string (nullable = true)\n",
      " |    |-- Form Factor: string (nullable = true)\n",
      " |    |-- Freezer Capacity: string (nullable = true)\n",
      " |    |-- Fuel Type: string (nullable = true)\n",
      " |    |-- Fuel type: string (nullable = true)\n",
      " |    |-- Handle Material: string (nullable = true)\n",
      " |    |-- Handle Type: string (nullable = true)\n",
      " |    |-- Handle/Lever Placement: string (nullable = true)\n",
      " |    |-- Heater Surface Material: string (nullable = true)\n",
      " |    |-- Heating Elements: string (nullable = true)\n",
      " |    |-- Heating Method: string (nullable = true)\n",
      " |    |-- Horsepower: string (nullable = true)\n",
      " |    |-- Hose Length: string (nullable = true)\n",
      " |    |-- Human Interface Input: string (nullable = true)\n",
      " |    |-- Ignition System Type: string (nullable = true)\n",
      " |    |-- Import: string (nullable = true)\n",
      " |    |-- Incandescent Equivalent Wattage: string (nullable = true)\n",
      " |    |-- Included Components: string (nullable = true)\n",
      " |    |-- Installation Method: string (nullable = true)\n",
      " |    |-- Installation Type: string (nullable = true)\n",
      " |    |-- International Shipping: string (nullable = true)\n",
      " |    |-- Is Discontinued By Manufacturer: string (nullable = true)\n",
      " |    |-- Is Dishwasher Safe: string (nullable = true)\n",
      " |    |-- Is Microwaveable: string (nullable = true)\n",
      " |    |-- Item Dimensions LxWxH: string (nullable = true)\n",
      " |    |-- Item Form: string (nullable = true)\n",
      " |    |-- Item Package Dimensions L x W x H: string (nullable = true)\n",
      " |    |-- Item Package Quantity: string (nullable = true)\n",
      " |    |-- Item Weight: string (nullable = true)\n",
      " |    |-- Item model number: string (nullable = true)\n",
      " |    |-- Light Color: string (nullable = true)\n",
      " |    |-- Light Type: string (nullable = true)\n",
      " |    |-- Lighting: string (nullable = true)\n",
      " |    |-- Manufacturer: string (nullable = true)\n",
      " |    |-- Manufacturer Part Number: string (nullable = true)\n",
      " |    |-- Manufacturer Warranty: string (nullable = true)\n",
      " |    |-- Material: string (nullable = true)\n",
      " |    |-- Material Type: string (nullable = true)\n",
      " |    |-- Max Spin Speed: string (nullable = true)\n",
      " |    |-- Maximum Power: string (nullable = true)\n",
      " |    |-- Maximum Pressure: string (nullable = true)\n",
      " |    |-- Maximum Rotational Speed: string (nullable = true)\n",
      " |    |-- Measurement Accuracy: string (nullable = true)\n",
      " |    |-- Measurement System: string (nullable = true)\n",
      " |    |-- Metal Type: string (nullable = true)\n",
      " |    |-- Model Info: string (nullable = true)\n",
      " |    |-- Model Name: string (nullable = true)\n",
      " |    |-- Mounting Type: string (nullable = true)\n",
      " |    |-- National Stock Number: string (nullable = true)\n",
      " |    |-- Noise: string (nullable = true)\n",
      " |    |-- Noise Level: string (nullable = true)\n",
      " |    |-- Number Of Pieces: string (nullable = true)\n",
      " |    |-- Number of Doors: string (nullable = true)\n",
      " |    |-- Number of Handles: string (nullable = true)\n",
      " |    |-- Number of Items: string (nullable = true)\n",
      " |    |-- Number of Pieces: string (nullable = true)\n",
      " |    |-- Number of Sets: string (nullable = true)\n",
      " |    |-- Number of pieces: string (nullable = true)\n",
      " |    |-- Operation Mode: string (nullable = true)\n",
      " |    |-- Option Cycles: string (nullable = true)\n",
      " |    |-- Other display features: string (nullable = true)\n",
      " |    |-- Outside Diameter: string (nullable = true)\n",
      " |    |-- Package Dimensions: string (nullable = true)\n",
      " |    |-- Package Type: string (nullable = true)\n",
      " |    |-- Package Weight: string (nullable = true)\n",
      " |    |-- Part Number: string (nullable = true)\n",
      " |    |-- Pattern: string (nullable = true)\n",
      " |    |-- Position: string (nullable = true)\n",
      " |    |-- Power Source: string (nullable = true)\n",
      " |    |-- Pre-printed: string (nullable = true)\n",
      " |    |-- Product Benefits: string (nullable = true)\n",
      " |    |-- Product Care Instructions: string (nullable = true)\n",
      " |    |-- Product Dimensions: string (nullable = true)\n",
      " |    |-- Recommended Uses For Product: string (nullable = true)\n",
      " |    |-- Refrigerant: string (nullable = true)\n",
      " |    |-- Refrigerator Fresh Food Capacity: string (nullable = true)\n",
      " |    |-- Reusability: string (nullable = true)\n",
      " |    |-- Room Type: string (nullable = true)\n",
      " |    |-- Runtime: string (nullable = true)\n",
      " |    |-- Scent: string (nullable = true)\n",
      " |    |-- Seasonal Energy Efficiency Ratio (SEER): string (nullable = true)\n",
      " |    |-- Shape: string (nullable = true)\n",
      " |    |-- Shelf Type: string (nullable = true)\n",
      " |    |-- Shelves: string (nullable = true)\n",
      " |    |-- Size: string (nullable = true)\n",
      " |    |-- Sound Level: string (nullable = true)\n",
      " |    |-- Special Feature: string (nullable = true)\n",
      " |    |-- Special Features: string (nullable = true)\n",
      " |    |-- Specification Met: string (nullable = true)\n",
      " |    |-- Speed: string (nullable = true)\n",
      " |    |-- Sport: string (nullable = true)\n",
      " |    |-- Standard Cycles: string (nullable = true)\n",
      " |    |-- Style: string (nullable = true)\n",
      " |    |-- Surface Recommendation: string (nullable = true)\n",
      " |    |-- Theme: string (nullable = true)\n",
      " |    |-- Thickness: string (nullable = true)\n",
      " |    |-- Thread Size: string (nullable = true)\n",
      " |    |-- Thread Type: string (nullable = true)\n",
      " |    |-- Type of Bulb: string (nullable = true)\n",
      " |    |-- Unit Count: string (nullable = true)\n",
      " |    |-- Upper Temperature Rating: string (nullable = true)\n",
      " |    |-- Usage: string (nullable = true)\n",
      " |    |-- Vehicle Service Type: string (nullable = true)\n",
      " |    |-- Voltage: string (nullable = true)\n",
      " |    |-- Warranty Description: string (nullable = true)\n",
      " |    |-- Wattage: string (nullable = true)\n",
      " |    |-- Wheel Width: string (nullable = true)\n",
      " |    |-- With Lid: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- hi_res: string (nullable = true)\n",
      " |    |    |-- large: string (nullable = true)\n",
      " |    |    |-- thumb: string (nullable = true)\n",
      " |    |    |-- variant: string (nullable = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- rating_number: long (nullable = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- videos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47066274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['average_rating',\n",
       " 'bought_together',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'details',\n",
       " 'features',\n",
       " 'images',\n",
       " 'main_category',\n",
       " 'parent_asin',\n",
       " 'price',\n",
       " 'rating_number',\n",
       " 'store',\n",
       " 'title',\n",
       " 'videos']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ac1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in meta that are not needed in the analysis\n",
    "\n",
    "cols_to_drop = ['images', 'videos', 'bought_together', 'price', 'rating_number', 'average_rating']\n",
    "\n",
    "df_meta = df_meta.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5228aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----+-----+\n",
      "|main_category|parent_asin|store|title|\n",
      "+-------------+-----------+-----+-----+\n",
      "|            1|          0|    6|    0|\n",
      "+-------------+-----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null or nan columns that don't contain arrays\n",
    "\n",
    "cols_non_arr = [c for c, t in df_meta.dtypes if (t.startswith('array')==False) and (t.startswith('struct') == False) ] \n",
    "\n",
    "df_meta.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in cols_non_arr]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3260639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate % of blanks in columns\n",
    "\n",
    "# for c in cols_non_arr:\n",
    "    \n",
    "#     print(f'Percentage of blank rows in {c}: {round(100 * df_meta.where(col(c).isNull() | isnan(c)).count() / df_meta.count(), 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f86230",
   "metadata": {},
   "source": [
    "### Cleaning Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2775d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape: (500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'Ratings shape: ({df_ratings.count()}, {len(df_ratings.columns)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c89b92bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin',\n",
       " 'helpful_vote',\n",
       " 'images',\n",
       " 'parent_asin',\n",
       " 'rating',\n",
       " 'text',\n",
       " 'timestamp',\n",
       " 'title',\n",
       " 'user_id',\n",
       " 'verified_purchase']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1398cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful_vote: long (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- attachment_type: string (nullable = true)\n",
      " |    |    |-- large_image_url: string (nullable = true)\n",
      " |    |    |-- medium_image_url: string (nullable = true)\n",
      " |    |    |-- small_image_url: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55104024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a284fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['title', 'text', 'images', 'helpful_vote', 'verified_purchase', 'timestamp' ]\n",
    "df_ratings = df_ratings.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b388ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_non_arr = [c for c, t in df_ratings.dtypes if (t.startswith('array')==False) and (t.startswith('struct') == False) ] \n",
    "\n",
    "# for c in cols_non_arr:\n",
    "#     print(f'Percentage of blank rows in {c}: {round(100 * df_ratings.where(col(c).isNull() | isnan(c)).count() / df_ratings.count(), 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59160b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "\n",
    "def meta_lookup(parent_asin:str):\n",
    "\n",
    "    return df_meta.filter(col('parent_asin') == parent_asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8027ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "\n",
    "def ratings_lookup(parent_asin:str):\n",
    "\n",
    "    return df_ratings.filter(col('parent_asin') == parent_asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f7506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= meta_lookup('B00Q4X2FSM')\n",
    "# x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc2ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try\n",
    "# df_meta.filter(col('parent_asin') == 'B07S9DJ2S2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e60cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try: \n",
    "# col_custom = list(F.col(f).alias(f) for f in  df_meta.columns) + list(map(lambda f: F.col(\"details\").getItem(f).alias(str(f)), [\"Brand\", \"Manufacturer\"]))\n",
    "# col_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a551187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try\n",
    "\n",
    "# df_meta.select(col_custom).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eb442db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count blank [stores]\n",
    "\n",
    "df_meta.filter(col('store').isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc4e8a",
   "metadata": {},
   "source": [
    "### FE: Create column -> Maker : Extract from Brand/Manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a3e7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for getting brand/manufacturer/distributor from details \n",
    "\n",
    "def get_maker(dict_col, key1, key2):\n",
    "    if dict_col is None:\n",
    "        return None\n",
    "    if key1 in dict_col and dict_col[key1]:\n",
    "        return dict_col[key1]\n",
    "    elif key2 in dict_col:\n",
    "        return dict_col[key2]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "get_maker_udf = F.udf(get_maker, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88093bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call udf get_maker to fill [details] with brand or manufacturer info\n",
    "\n",
    "df_meta = df_meta.withColumn(\n",
    "    \"maker\",\n",
    "    get_maker_udf(df_meta[\"details\"], \\\n",
    "                F.lit(\"Brand\"), \\\n",
    "                F.lit(\"Manufacturer\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8c3404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show null values in maker column\n",
    "\n",
    "df_meta.where(col('maker').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7f1a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since [store] values will be used for maker, ensure there'e no blank values \n",
    "df_meta = df_meta.na.fill({'store':'Unknown'})\n",
    "\n",
    "# Checkpoint: Assert no remaining nulls in [store]\n",
    "assert df_meta.filter(col('store').isNull()).count() == 0, 'Blank values in store. Check imputation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2be98640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null columns in [maker] with values from [store]\n",
    "from pyspark.sql.functions import coalesce\n",
    "df_meta = df_meta.withColumn('maker', coalesce('maker', 'store') )\n",
    "\n",
    "# Checkpoint: Assert no remaining nulls in [maker]\n",
    "assert df_meta.filter(col('maker').isNull()).count() == 0, 'Blank values in maker. Check imputation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e93ef",
   "metadata": {},
   "source": [
    "### FE: Create column -> Feature_Group : Concatenation of different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbaccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the concatenated values of the columns of interest\n",
    "cols_of_interest = ['parent_asin', 'main_category', 'maker', 'title' ] # Add desc and details later\n",
    "df_meta = df_meta.withColumn('feature_group', concat_ws(' ', *cols_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684bcb9",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa7c61a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/edu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/edu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7746f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d245979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for preprocessing text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Register the UDF\n",
    "preprocess_text_udf = F.udf(preprocess_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bdf745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF to the 'text' column\n",
    "df_meta = df_meta.withColumn('feat_preproc', preprocess_text_udf(df_meta['feature_group']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590c46e",
   "metadata": {},
   "source": [
    "#### Tokenizing the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ac5b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the preprocessed text \n",
    "tokenizer = Tokenizer(inputCol='feat_preproc', outputCol='feat_tokens')\n",
    "df_tokenized = tokenizer.transform(df_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e95c9e",
   "metadata": {},
   "source": [
    "#### Add Extra Lemmatization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a8d0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF: Lemmatize tokens\n",
    "import numpy as np\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Lemmatize the input tokens.\n",
    "    Args:\n",
    "        tokens (list): List of tokens to lemmatize.\n",
    "    Returns:\n",
    "        list: List of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    if tokens is None:\n",
    "        return None\n",
    "\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token not in stop_words]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Register the UDF\n",
    "lemmatize_tokens_udf = F.udf(lemmatize_tokens, ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01b170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF to the 'tokens' column\n",
    "\n",
    "df_lemmatized = df_tokenized.withColumn('feat_lemma', lemmatize_tokens_udf(df_tokenized['feat_tokens']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d47c16",
   "metadata": {},
   "source": [
    "#### Creating Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43005d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctvec_file = None\n",
    "hashtf_file = None\n",
    "tf_ctvector = None\n",
    "tf_vector = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2619e54",
   "metadata": {},
   "source": [
    "##### A. Using Hashing Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16f01219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Hashing Term Frequency to create feature vectors - Similar to TF-IDF but without the IDF component\\n# The HashingTF class is used to convert a sequence of terms into a feature vector using the hashing trick.\\n# HashingTF is a feature transformer that maps a sequence of terms to their term frequencies using the hashing trick.\\n# It is a fast and efficient way to convert text data into numerical feature vectors.\\n# The numFeatures parameter specifies the number of features to create.\\n# The output is a sparse vector of term frequencies, where each index corresponds to a hashed term.\\n\\n\\nhashingTF = HashingTF(inputCol=\"feat_lemma\", outputCol=\"feat_vectors\" ) #, numFeatures=2048)\\ntf_vector = hashingTF.transform(df_lemmatized)\\n\\ntf_vector.cache()\\ntf_vector.select(col(\\'feat_vectors\\')).show(5)\\n\\nctvec_file = None\\nhashtf_file = \\'./data/similarity_hashtf.csv\\' \\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Hashing Term Frequency to create feature vectors - Similar to TF-IDF but without the IDF component\n",
    "# The HashingTF class is used to convert a sequence of terms into a feature vector using the hashing trick.\n",
    "# HashingTF is a feature transformer that maps a sequence of terms to their term frequencies using the hashing trick.\n",
    "# It is a fast and efficient way to convert text data into numerical feature vectors.\n",
    "# The numFeatures parameter specifies the number of features to create.\n",
    "# The output is a sparse vector of term frequencies, where each index corresponds to a hashed term.\n",
    "\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"feat_lemma\", outputCol=\"feat_vectors\" ) #, numFeatures=2048)\n",
    "tf_vector = hashingTF.transform(df_lemmatized)\n",
    "\n",
    "tf_vector.cache()\n",
    "tf_vector.select(col('feat_vectors')).show(5)\n",
    "\n",
    "ctvec_file = None\n",
    "hashtf_file = './data/similarity_hashtf.csv' \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002abfc",
   "metadata": {},
   "source": [
    "##### B. Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03ff10f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[categories: array<string>, description: array<string>, details: struct<Access Location:string,Age Range (Description):string,Air Flow Capacity:string,Airflow Displacement:string,Alarm:string,Amperage Capacity:string,Annual Energy Consumption:string,Are Batteries Included:string,Assembly required:string,Backlight:string,Batteries:string,Batteries Included?:string,Batteries Required?:string,Batteries required:string,Battery Cell Type:string,Best Sellers Rank:struct<Amazon Renewed:bigint,Appliances:bigint,Beverage Refrigerators:bigint,Chest Freezers:bigint,Clothes Dryer Replacement Lint Screens:bigint,Clothes Dryer Replacement Vents:bigint,Clothes Washer Replacement Doors:bigint,Clothes Washer Replacement Drain Pumps:bigint,Clothes Washing Machines:bigint,Commercial Bag Sealers:bigint,Commercial Shrink Wrappers:bigint,Compact Refrigerators:bigint,Cooktop Parts & Accessories:bigint,Cooktops:bigint,Dishwasher Parts & Accessories:bigint,Dishwasher Replacement Baskets:bigint,Dishwasher Replacement Hoses:bigint,Disposable Coffee Filters:bigint,Dryer Replacement Parts:bigint,Espresso Steaming Pitchers:bigint,Freezer Parts & Accessories:bigint,Health & Household:bigint,Home & Kitchen:bigint,Humidifier Accessories:bigint,Humidifier Humidity Meters:bigint,Humidifier Parts & Accessories:bigint,Humidifier Replacement Wicks:bigint,Ice Makers:bigint,In-Refrigerator Water Filters:bigint,Industrial & Scientific:bigint,Jugs:bigint,Kitchen & Dining:bigint,Oven Parts & Accessories:bigint,Paper & Plastic Household Supplies:bigint,Parts & Accessories:bigint,Permanent Coffee Filters:bigint,Portable Clothes Washing Machines:bigint,Portable Dryers:bigint,Range Accessories:bigint,Range Hood Filters:bigint,Range Hoods:bigint,Range Parts & Accessories:bigint,Range Replacement Burners:bigint,Range Replacement Drip Pans:bigint,Range Replacement Knobs:bigint,Refrigerator Egg Trays:bigint,Refrigerator Parts & Accessories:bigint,Refrigerator Replacement Bins:bigint,Refrigerator Replacement Handles:bigint,Refrigerator Replacement Ice Makers:bigint,Refrigerator Replacement Motors:bigint,Refrigerator Replacement Shelves:bigint,Refrigerators:bigint,Reusable Coffee Filters:bigint,Tools & Home Improvement:bigint,Washer Parts & Accessories:bigint>,Brand:string,Brand Name:string,Bulb Base:string,Bulb Shape Size:string,Burner type:string,Capacity:string,Capacity Name:string,Capacity Total:string,Care instructions:string,Center To Center Spacing:string,Certification:string,Closure Type:string,Color:string,Color Temperature:string,Compatible Device:string,Compatible Devices:string,Configuration:string,Connectivity Technology:string,Connector Type:string,Contains Liquid Contents:string,Control Console:string,Control Method:string,Control Type:string,Controller Type:string,Controls Type:string,Cooling Power:string,Cooling Vents:string,Cord Length:string,Country of Origin:string,Cycle Options:string,Date First Available:string,Defrost:string,Defrost System:string,Department:string,Diameter:string,Domestic Shipping:string,Door Hinges:string,Door Material Type:string,Drawer Type:string,Duration:string,Efficiency:string,Energy Star:string,Exterior:string,Exterior Finish:string,External Testing Certification:string,Finish:string,Finish Type:string,Finish types:string,Floor Area:string,Flow Rate:string,Form Factor:string,Freezer Capacity:string,Fuel Type:string,Fuel type:string,Handle Material:string,Handle Type:string,Handle/Lever Placement:string,Heater Surface Material:string,Heating Elements:string,Heating Method:string,Horsepower:string,Hose Length:string,Human Interface Input:string,Ignition System Type:string,Import:string,Incandescent Equivalent Wattage:string,Included Components:string,Installation Method:string,Installation Type:string,International Shipping:string,Is Discontinued By Manufacturer:string,Is Dishwasher Safe:string,Is Microwaveable:string,Item Dimensions LxWxH:string,Item Form:string,Item Package Dimensions L x W x H:string,Item Package Quantity:string,Item Weight:string,Item model number:string,Light Color:string,Light Type:string,Lighting:string,Manufacturer:string,Manufacturer Part Number:string,Manufacturer Warranty:string,Material:string,Material Type:string,Max Spin Speed:string,Maximum Power:string,Maximum Pressure:string,Maximum Rotational Speed:string,Measurement Accuracy:string,Measurement System:string,Metal Type:string,Model Info:string,Model Name:string,Mounting Type:string,National Stock Number:string,Noise:string,Noise Level:string,Number Of Pieces:string,Number of Doors:string,Number of Handles:string,Number of Items:string,Number of Pieces:string,Number of Sets:string,Number of pieces:string,Operation Mode:string,Option Cycles:string,Other display features:string,Outside Diameter:string,Package Dimensions:string,Package Type:string,Package Weight:string,Part Number:string,Pattern:string,Position:string,Power Source:string,Pre-printed:string,Product Benefits:string,Product Care Instructions:string,Product Dimensions:string,Recommended Uses For Product:string,Refrigerant:string,Refrigerator Fresh Food Capacity:string,Reusability:string,Room Type:string,Runtime:string,Scent:string,Seasonal Energy Efficiency Ratio (SEER):string,Shape:string,Shelf Type:string,Shelves:string,Size:string,Sound Level:string,Special Feature:string,Special Features:string,Specification Met:string,Speed:string,Sport:string,Standard Cycles:string,Style:string,Surface Recommendation:string,Theme:string,Thickness:string,Thread Size:string,Thread Type:string,Type of Bulb:string,Unit Count:string,Upper Temperature Rating:string,Usage:string,Vehicle Service Type:string,Voltage:string,Warranty Description:string,Wattage:string,Wheel Width:string,With Lid:string>, features: array<string>, main_category: string, parent_asin: string, store: string, title: string, maker: string, feature_group: string, feat_preproc: string, feat_tokens: array<string>, feat_lemma: array<string>, feat_vectors: vector]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Apply CountVectorizer to count the occurrences of each phrase\n",
    "countvec = CountVectorizer(inputCol=\"feat_lemma\", outputCol=\"feat_vectors\")\n",
    "\n",
    "countvec_model = countvec.fit(df_lemmatized)\n",
    "tf_ctvector = countvec_model.transform(df_lemmatized)\n",
    "\n",
    "hashtf_file = None\n",
    "ctvec_file = './data/similarity_ctvec.csv'\n",
    "\n",
    "tf_ctvector.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f42a639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------------------+--------------------+-----------+------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          categories|         description|             details|              features|       main_category|parent_asin|             store|               title|             maker|       feature_group|        feat_preproc|         feat_tokens|          feat_lemma|        feat_vectors|\n",
      "+--------------------+--------------------+--------------------+----------------------+--------------------+-----------+------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|                    []|Tools & Home Impr...| B07CPY3X2X|            UMTELE|Compatible with L...|            UMTELE|B07CPY3X2X Tools ...|b07cpy3x2x tools ...|[b07cpy3x2x, tool...|[b07cpy3x2x, tool...|(3054,[0,1,2,4,6,...|\n",
      "|[Appliances, Part...|[8268961 Dishwash...|{NULL, NULL, NULL...|  [8268961 2pcs Dis...|Tools & Home Impr...| B09JYZZ8NQ|           GZsenwo|8268961 Dishwashe...|           GZsenwo|B09JYZZ8NQ Tools ...|b09jyzz8nq tools ...|[b09jyzz8nq, tool...|[b09jyzz8nq, tool...|(3054,[0,1,2,3,17...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|                    []|Tools & Home Impr...| B0824J3GGJ|                WY|Dryer Belt Replac...|                WY|B0824J3GGJ Tools ...|b0824j3ggj tools ...|[b0824j3ggj, tool...|[b0824j3ggj, tool...|(3054,[0,1,2,3,7,...|\n",
      "|[Appliances, Part...|[Fit Models: RF22...|{NULL, NULL, NULL...|  [DA97-12942A This...|Tools & Home Impr...| B09Y5T57KX|           TNITRIB|Optimize and Upgr...|           TNITRIB|B09Y5T57KX Tools ...|b09y5t57kx tools ...|[b09y5t57kx, tool...|[b09y5t57kx, tool...|(3054,[0,1,2,11,1...|\n",
      "|[Appliances, Dish...|[Get better resul...|{NULL, NULL, NULL...|                    []|          Appliances| B0052EK0MW|        KitchenAid|KitchenAid Superb...|        KitchenAid|B0052EK0MW Applia...|b0052ek0mw applia...|[b0052ek0mw, appl...|[b0052ek0mw, appl...|(3054,[5,18,29,31...|\n",
      "|[Appliances, Part...|[Large Capacity E...|{NULL, NULL, NULL...|  [Auto Rolling Egg...|Tools & Home Impr...| B0B2NP5QQT|             TOGOO|Large Capacity Eg...|             TOGOO|B0B2NP5QQT Tools ...|b0b2np5qqt tools ...|[b0b2np5qqt, tool...|[b0b2np5qqt, tool...|(3054,[0,1,2,6,35...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|[PARTS NUMBERTh...|          Appliances| B07W42P978|         AMI PARTS|WD12X10327 Rack R...|         AMI PARTS|B07W42P978 Applia...|b07w42p978 applia...|[b07w42p978, appl...|[b07w42p978, appl...|(3054,[5,9,13,28,...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|[Worth buyingSu...|Tools & Home Impr...| B09XQT8Q9X|           UPTTHOW|UPTTHOW Upgraded ...|           UPTTHOW|B09XQT8Q9X Tools ...|b09xqt8q9x tools ...|[b09xqt8q9x, tool...|[b09xqt8q9x, tool...|(3054,[0,1,2,7,9,...|\n",
      "|[Appliances, Part...|[Brand new dryer ...|{NULL, NULL, NULL...|                    []|Tools & Home Impr...| B00IN9AGAE|                GE|Clothes Dryer Dru...|               RPI|B00IN9AGAE Tools ...|b00in9agae tools ...|[b00in9agae, tool...|[b00in9agae, tool...|(3054,[0,1,2,10,3...|\n",
      "|[Appliances, Part...|[SPECIFICATIONS, ...|{NULL, NULL, NULL...|  [VULCAN-HART, Ove...|Industrial & Scie...| B00NXW96TS|       Vulcan Hart|Vulcan Hart VULCA...|       Vulcan Hart|B00NXW96TS Indust...|b00nxw96ts indust...|[b00nxw96ts, indu...|[b00nxw96ts, indu...|(3054,[17,22,40,5...|\n",
      "|[Appliances, Part...|[This part shines...|{NULL, NULL, NULL...|  [Replacement ice ...|Tools & Home Impr...| B07BBF44DQ|            Siwdoy|Siwdoy 4389102 Co...|            Siwdoy|B07BBF44DQ Tools ...|b07bbf44dq tools ...|[b07bbf44dq, tool...|[b07bbf44dq, tool...|(3054,[0,1,2,3,12...|\n",
      "|[Appliances, Part...|[A washing machin...|{NULL, NULL, NULL...|  [ Model Number 4...|Tools & Home Impr...| B07VVR2TNH|       Repairwares|Repairwares Washi...|       Repairwares|B07VVR2TNH Tools ...|b07vvr2tnh tools ...|[b07vvr2tnh, tool...|[b07vvr2tnh, tool...|(3054,[0,1,2,11,2...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|                    []|Tools & Home Impr...| B078QB5M4B|After Market Parts|Compatible Oven o...|After Market Parts|B078QB5M4B Tools ...|b078qb5m4b tools ...|[b078qb5m4b, tool...|[b078qb5m4b, tool...|(3054,[0,1,2,9,12...|\n",
      "|[Appliances, Part...|[Innovative Premi...|{NULL, NULL, NULL...| [Strong Water Ab...|         Amazon Home| B09XQTY1X8|            TAUPTT|TAUPTT Refrigerat...|            TAUPTT|B09XQTY1X8 Amazon...|b09xqty1x8 amazon...|[b09xqty1x8, amaz...|[b09xqty1x8, amaz...|(3054,[0,6,8,11,1...|\n",
      "|[Appliances, Part...|[Compatible with ...|{NULL, NULL, NULL...| [Upgraded to Foo...|Tools & Home Impr...| B09F2Y7CLZ|              LXun|Lxun Upgraded AAP...|              LXun|B09F2Y7CLZ Tools ...|b09f2y7clz tools ...|[b09f2y7clz, tool...|[b09f2y7clz, tool...|(3054,[0,1,2,6,12...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|                    []|Tools & Home Impr...| B07Q24SNJ2|          Abutilon|Abutilon Dishwash...|          Abutilon|B07Q24SNJ2 Tools ...|b07q24snj2 tools ...|[b07q24snj2, tool...|[b07q24snj2, tool...|(3054,[0,1,2,3,18...|\n",
      "|[Appliances, Part...| [Whirlpool Igniter]|{NULL, NULL, NULL...|  [This is a Genuin...|Tools & Home Impr...| B07QZHQTVJ|         Whirlpool|Whirlpool W109185...|         Whirlpool|B07QZHQTVJ Tools ...|b07qzhqtvj tools ...|[b07qzhqtvj, tool...|[b07qzhqtvj, tool...|(3054,[0,1,2,3,40...|\n",
      "|[Appliances, Part...|[This is an After...|{NULL, NULL, NULL...|  [This is an After...|Tools & Home Impr...| B006R6N2WO|        FRIGIDAIRE|Front Drum Felt &...|             Supco|B006R6N2WO Tools ...|b006r6n2wo tools ...|[b006r6n2wo, tool...|[b006r6n2wo, tool...|(3054,[0,1,2,23,3...|\n",
      "|[Appliances, Part...|[Samsung Range/St...|{NULL, NULL, NULL...|  [Samsung ASSY VAL...|Tools & Home Impr...| B00YZ50ZTM|           SAMSUNG|Samsung DG94-0093...|           Samsung|B00YZ50ZTM Tools ...|b00yz50ztm tools ...|[b00yz50ztm, tool...|[b00yz50ztm, tool...|(3054,[0,1,2,9,14...|\n",
      "|[Appliances, Part...|                  []|{NULL, NULL, NULL...|  [COMPATIBLE REPLA...|         Amazon Home| B06XP2NFXL|             Tier1|Tier1 5 Micron 10...|             Tier1|B06XP2NFXL Amazon...|b06xp2nfxl amazon...|[b06xp2nfxl, amaz...|[b06xp2nfxl, amaz...|(3054,[0,4,7,8,11...|\n",
      "+--------------------+--------------------+--------------------+----------------------+--------------------+-----------+------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tf_ctvector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f5398",
   "metadata": {},
   "source": [
    "Create IDF for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dfce14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# The IDF class is used to compute the inverse document frequency (IDF) of the terms in the feature vectors.\n",
    "# The IDF component is used to down-weight the importance of common terms and up-weight the importance of rare terms.\n",
    "\n",
    "idf = IDF(inputCol=\"feat_vectors\", outputCol=\"feat_idf\")\n",
    "\n",
    "if tf_ctvector:\n",
    "        idf_model = idf.fit(tf_ctvector)\n",
    "        tfidf = idf_model.transform(tf_ctvector)\n",
    "elif tf_vector:\n",
    "        idf_model = idf.fit(tf_vector)\n",
    "        tfidf = idf_model.transform(tf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f2e389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in the tfidf vector \n",
    "cols_to_drop = ['feat_preproc', 'feat_tokens', 'feat_lemma', 'feat_vectors']\n",
    "tfidf = tfidf.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96eafd1",
   "metadata": {},
   "source": [
    "Create a database view of the vectorized tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40f2de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.createOrReplaceTempView(\"v_meta_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5106b7",
   "metadata": {},
   "source": [
    "##### Build query in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37048b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF: Query builder using SQL \n",
    "\n",
    "def query_builder(search_asin = None, search_category = None, search_maker = None, search_title = None):\n",
    "    \"\"\"\n",
    "    Build a SQL query to filter the DataFrame based on the provided search criteria.\n",
    "\n",
    "    Args:\n",
    "        search_category (str, optional): Category to search for. Defaults to None.\n",
    "        search_maker (str, optional): Maker to search for. Defaults to None.\n",
    "        search_title (str, optional): Title to search for. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: SQL query string.\n",
    "    \"\"\"\n",
    "\n",
    "    conditions = []\n",
    "    if search_asin:\n",
    "        conditions.append(f\" parent_asin = '{search_asin}'\")\n",
    "    if search_category:\n",
    "        conditions.append(f\" main_category LIKE '%{search_category}%'\")\n",
    "    if search_maker:\n",
    "        # conditions.append(f\" maker LIKE '%{search_maker}%'\")\n",
    "        conditions.append(f\" maker = '{search_maker}'\")\n",
    "    if search_title:\n",
    "        conditions.append(f\" title LIKE '%{search_title}%'\")\n",
    "    if not conditions:\n",
    "        raise ValueError(\"At least one search criterion must be provided.\")\n",
    "    \n",
    "    conditions_str = \" AND \".join(conditions)\n",
    "\n",
    "    query = f\"SELECT * FROM v_meta_tfidf WHERE ({conditions_str})\"\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69957174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try: Test Cases\n",
    "\n",
    "\n",
    "# # Test Case #1: Search by category and maker/brand\n",
    "# query_statement = query_builder(search_asin=None, search_category='Amazon Home', search_maker='Frigidaire' )\n",
    "\n",
    "# # Test Case #2: Seacrh by category, maker, and title\n",
    "# # query_statement = query_builder(search_asin= None, search_category='Electronics', search_maker='Samsung', search_title='DC66')\n",
    "\n",
    "# # print(query_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "153b1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results from sql query \n",
    "# query_results = spark.sql(query_statement)\n",
    "# print(f'Query results count: {query_results.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe37b36",
   "metadata": {},
   "source": [
    "#### Transform Query Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b230dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_query = [input('Enter Product To Search: ') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8819a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frigidaire refrigirators\n"
     ]
    }
   ],
   "source": [
    "# Validate:\n",
    "input_query = 'Frigidaire refrigirators'\n",
    "print( input_query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ae25cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to spark dataframe\n",
    "input_df = spark.createDataFrame([(input_query,)], ['feat_preproc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "782855d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the input query\n",
    "query_pp = preprocess_text_udf(input_query)\n",
    "\n",
    "# Transform input query to a pyspark dataframe\n",
    "# query_pp_df = spark.createDataFrame([query_pp], StringType()).toDF('feat_preproc')\n",
    "query_pp_df = spark.createDataFrame([(input_query,)], ['feat_preproc'])\n",
    "\n",
    "# Tokenize the preprocessed text\n",
    "query_token = tokenizer.transform(query_pp_df)\n",
    "\n",
    "# Lemmatize the tokens\n",
    "query_lemma = query_token.withColumn('feat_lemma', lemmatize_tokens_udf(query_token['feat_tokens']))\n",
    "\n",
    "# Get term frequency vector for the lemmatized tokens\n",
    "query_tf = countvec_model.transform(query_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11d7eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|        feat_preproc|         feat_tokens|\n",
      "+--------------------+--------------------+\n",
      "|Frigidaire refrig...|[frigidaire, refr...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_token.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0eb9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|        feat_preproc|         feat_tokens|          feat_lemma|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Frigidaire refrig...|[frigidaire, refr...|[frigidaire, refr...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query_lemma.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07377193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+\n",
      "|        feat_preproc|         feat_tokens|          feat_lemma|     feat_vectors|\n",
      "+--------------------+--------------------+--------------------+-----------------+\n",
      "|Frigidaire refrig...|[frigidaire, refr...|[frigidaire, refr...|(5165,[17],[1.0])|\n",
      "+--------------------+--------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_tf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d8224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.===>                     (5 + 3) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/edu/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o344.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get the IDF vector for the term frequency vector\u001b[39;00m\n\u001b[32m      2\u001b[39m idf = IDF(inputCol=\u001b[33m\"\u001b[39m\u001b[33mfeat_vectors\u001b[39m\u001b[33m\"\u001b[39m, outputCol=\u001b[33m\"\u001b[39m\u001b[33mquery_idf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m idf_model = \u001b[43midf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_tf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m query_tfidf = idf_model.transform(query_tf)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# query_tfidf.cache()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/pyspark/ml/base.py:205\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._fit(dataset)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[32m    210\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/pyspark/ml/wrapper.py:381\u001b[39m, in \u001b[36mJavaEstimator._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) -> JM:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     java_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m     model = \u001b[38;5;28mself\u001b[39m._create_model(java_model)\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copyValues(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/pyspark/ml/wrapper.py:378\u001b[39m, in \u001b[36mJavaEstimator._fit_java\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/CapstoneProjects/Spark_RecSys/venv_spark/lib/python3.12/site-packages/py4j/protocol.py:334\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    335\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    336\u001b[39m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name))\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28mtype\u001b[39m = answer[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mPy4JError\u001b[39m: An error occurred while calling o344.fit"
     ]
    }
   ],
   "source": [
    "# Get the IDF vector for the term frequency vector\n",
    "idf = IDF(inputCol=\"feat_vectors\", outputCol=\"query_idf\")\n",
    "idf_model = idf.fit(query_tf)\n",
    "\n",
    "query_tfidf = idf_model.transform(query_tf)\n",
    "# query_tfidf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e9c5d",
   "metadata": {},
   "source": [
    "### Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab to self?\n",
    "\n",
    "# tfidf = tfidf.crossJoin(tfidf.withColumnRenamed(\"feat_idf\", \"feat_idf2\"))\n",
    "# tfidf.show(2)\n",
    "# tfidf.select( 'feat_idf', 'feat_idf2').show(5, truncate=False)\n",
    "# similarity = tfidf.withColumn(\"cos_sim\", cos_sim(F.col('feat_idf'), F.col('feat_idf2')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF: Cosine Similarity\n",
    "\n",
    "# @F.udf(returnType=FloatType())\n",
    "def cos_sim(u, v):\n",
    "\n",
    "  return float(u.dot(v) / (u.norm(2) * v.norm(2)))\n",
    "\n",
    "# Register the UDF\n",
    "cos_sim_udf = F.udf(cos_sim, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_results.select(col('feat_idf')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818cda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validate query results from previous call\n",
    "\n",
    "print(query_tfidf.count())\n",
    "query_tfidf.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the tfidf vectors and the query results.\n",
    "\n",
    "similarity = tfidf.withColumn(\"cos_sim\", \\\n",
    "                              cos_sim_udf(tfidf['feat_idf'], query_tfidf['query_idf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the similarity results\n",
    "\n",
    "similarity.select('parent_asin', 'cos_sim', 'title', 'main_category', 'maker').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f260504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation: Save similarity results to csv. \n",
    "# Toggle below codes to save using hasftf or countvectorizer.\n",
    "\n",
    "n_result = 20\n",
    "\n",
    "\n",
    "df_cos_sim = similarity.select('parent_asin', 'cos_sim', 'title', 'main_category', 'maker').toPandas().sort_values('cos_sim', ascending=False)\n",
    "df_cos_sim = df_cos_sim.head(n_result)\n",
    "\n",
    "\n",
    "if hashtf_file:\n",
    "    # similarity.select('parent_asin', 'cos_sim', 'title', 'main_category', 'maker').show(10, truncate=False).toPandas().sort_values('cos_sim', ascending=False).head(10)\n",
    "\n",
    "    df_cos_sim.to_csv(hashtf_file, index=False)\n",
    "\n",
    "elif ctvec_file:\n",
    "    \n",
    "    df_cos_sim.to_csv(ctvec_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feeb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity.select('parent_asin', 'cos_sim', 'title', 'main_category', 'maker').show(10, truncate=False).toPandas().sort_values('cos_sim', ascending=False).head(10)\n",
    "# similarity.select('parent_asin', 'cos_sim', 'title', 'main_category', 'maker').toPandas().sort_values('cos_sim', ascending=False).to_csv('./data/similarity_hashtf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad26907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity = cosine_similarity(idfscores.select('feat_idf').rdd.map(lambda x: x[0]).collect())\n",
    "# similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and fit the MinHashLSH model to the feature vectors\n",
    "# # Notes:\n",
    "# # The MinHashLSH -  creates a locality-sensitive hashing (LSH) model for approximate nearest neighbor search.\n",
    "# # numHashTable -  number of hash tables to use for the LSH model.\n",
    "# # Fitted hash results -  transforms the feature vectors into hash values.\n",
    "\n",
    "\n",
    "# mh = MinHashLSH(inputCol=\"idf\", outputCol=\"mh_hashes\", numHashTables=5)\n",
    "# mh_model = mh.fit(idfscores)\n",
    "\n",
    "# # Transform the feature data to include hash values\n",
    "# transformedData = mh_model.transform(idfscores)\n",
    "# transformedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884e096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta.withColumn('c_brand', F.col('details').getItem('Brand')).show(5)\n",
    "\n",
    "# df_meta.withColumn('c_manufac', F.col('details').getItem('Manufacturer')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b051af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.withColumn('c_brand', F.col('details').getItem('Brand')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd = spark.sparkContext.parallelize([jsonData])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
